{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/dev/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3 \n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "import os \n",
    "from PIL import Image\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sagemaker.multidatamodel import MultiDataModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.getenv(\"BUCKET\")\n",
    "role_arn = os.getenv(\"ROLE_ARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Loaded sucesfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not bucket  and role_arn:\n",
    "    \n",
    "    raise ValueError(\"Enviroment Variables are not configured\")\n",
    "\n",
    "else: print(\"Variables Loaded sucesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data =  f'{bucket}data'\"\n",
    "training_data = f'{bucket}mxnet_data'\n",
    "s3_output_path = f'{bucket}output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16 & Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'epochs': 10,                       \n",
    "    'batch_size': 48,                   \n",
    "    'learning_rate': 0.0003,            \n",
    "    'weight_decay': 0.00005,            # Regularización ligera\n",
    "    'early_stopping': True,\n",
    "    'use_sampler': True,                # Crítico para detectar defectos\n",
    "    'augmentation_intensity': 0.8,      # Máximo aumento para casos raros\n",
    "    'dropout_rate': 0.4,                # Regularización moderada\n",
    "    'patience': 10,                     # Más tolerancia para aprendizaje fino\n",
    "    # 'optimizer': 'AdamW',             # Optimizador recomendado\n",
    "    # 'scheduler': 'ReduceLROnPlateau', # Ajuste automático de LR\n",
    "    'val_split': 0.2,                  \n",
    "    'threshold': 0.85                   # Umbral de confianza para producción\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'VGG16'\n",
    "model_name = 'Resnet18'\n",
    "model_name = 'SimpleCNN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point='train.py',  \n",
    "    source_dir='src',\n",
    "    role=role_arn,\n",
    "    instance_count=1,  \n",
    "    instance_type='ml.g4dn.xlarge', \n",
    "    # instance_type ='ml.m5.large',\n",
    "    framework_version='1.12.0', \n",
    "    py_version='py38',  \n",
    "    hyperparameters=hyperparameters,\n",
    "    base_job_name=f\"{model_name}-{datetime.now().strftime('%Y%m%d-%H%M')}\",\n",
    "    output_path= bucket + \"output\",  \n",
    "    sagemaker_session=sess,\n",
    "    use_spot_intances=True,\n",
    "    # max_wait=7200,\n",
    "    max_run=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS MXnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"num_classes\": 2,\n",
    "    \"num_training_samples\": 4000,  \n",
    "    \"image_shape\": \"3,224,224\",    \n",
    "    \"epochs\": 20,\n",
    "    \"mini_batch_size\": 48,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"use_pretrained_model\": 1,\n",
    "    'weight_decay': 0.00005,           \n",
    "    'early_stopping': True\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "estimator = MXNet(\n",
    "    entry_point='train.py',\n",
    "    framework_version='1.9.0',\n",
    "    py_version='py38',\n",
    "    hyperparameters=hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"MXnet\"\n",
    "\n",
    "training_image = retrieve(framework=\"image-classification\", region=region, version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role_arn,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge', \n",
    "    # instance_type = 'ml.p3.2xlarge,'\n",
    "    # instance_type ='ml.m5.large',\n",
    "    base_job_name=f\"{model_name}-{datetime.now().strftime('%Y%m%d-%H%M')}\",\n",
    "    hyperparameters=hyperparams,\n",
    "    output_path=s3_output_path\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_imgs = f\"{training_data}/train\"\n",
    "s3_valid_imgs = f'{training_data}/validation'\n",
    "s3_train_annot = f'{training_data}/train_lst'\n",
    "s3_valid_annot = f'{training_data}/validation_lst'\n",
    "\n",
    "train_imgs = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_imgs,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "valid_imgs = sagemaker.inputs.TrainingInput(\n",
    "    s3_valid_imgs,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "train_annot = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_annot,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "valid_annot = sagemaker.inputs.TrainingInput(\n",
    "    s3_valid_annot,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/jpeg\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": train_imgs,\n",
    "    \"validation\": valid_imgs,\n",
    "    \"train_lst\": train_annot,\n",
    "    \"validation_lst\": valid_annot,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: MXnet-20250524-0037-2025-05-24-05-47-56-804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-24 05:48:02 Starting - Starting the training job...\n",
      "2025-05-24 05:48:18 Starting - Preparing the instances for training...\n",
      "2025-05-24 05:48:45 Downloading - Downloading input data...\n",
      "2025-05-24 05:49:20 Downloading - Downloading the training image...............\n",
      "2025-05-24 05:51:53 Training - Training image download completed. Training in progress..Docker entrypoint called with argument(s): train\n",
      "Running default environment configuration script\n",
      "Nvidia gpu devices, drivers and cuda toolkit versions (only available on hosts with GPU):\n",
      "Sat May 24 05:52:08 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   22C    P8              8W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "Checking for nvidia driver and cuda compatibility.\n",
      "CUDA Compatibility driver provided.\n",
      "Proceeding with compatibility check between driver, cuda-toolkit and cuda-compat.\n",
      "Detected cuda-toolkit version: 11.1.\n",
      "Detected cuda-compat version: 455.32.00.\n",
      "Detected Nvidia driver version: 550.163.01.\n",
      "Nvidia driver compatible with cuda-toolkit. Disabling cuda-compat.\n",
      "/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\n",
      "[05/24/2025 05:52:11 INFO 140453719336768] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/image_classification/default-input.json: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32'}\n",
      "[05/24/2025 05:52:11 INFO 140453719336768] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '40', 'image_shape': '3,224,224', 'learning_rate': '0.0003', 'mini_batch_size': '48', 'num_classes': '2', 'num_training_samples': '4000', 'use_pretrained_model': '1'}\n",
      "[05/24/2025 05:52:11 INFO 140453719336768] Final configuration: {'use_pretrained_model': '1', 'num_layers': 152, 'epochs': '40', 'learning_rate': '0.0003', 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': '48', 'image_shape': '3,224,224', 'precision_dtype': 'float32', 'num_classes': '2', 'num_training_samples': '4000'}\n",
      "[05/24/2025 05:52:11 INFO 140453719336768] Searching for .lst files in /opt/ml/input/data/train_lst.\n",
      "[05/24/2025 05:52:11 INFO 140453719336768] Creating record files for train.lst\n",
      "[05/24/2025 05:52:38 INFO 140453719336768] Done creating record files...\n",
      "[05/24/2025 05:52:38 INFO 140453719336768] Searching for .lst files in /opt/ml/input/data/validation_lst.\n",
      "[05/24/2025 05:52:38 INFO 140453719336768] Creating record files for validation.lst\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] Done creating record files...\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] use_pretrained_model: 1\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] multi_label: 0\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] Using pretrained model for initializing weights and transfer learning.\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] ---- Parameters ----\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] num_layers: 152\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] data type: <class 'numpy.float32'>\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] epochs: 40\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] optimizer: sgd\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] momentum: 0.9\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] weight_decay: 0.0001\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] learning_rate: 0.0003\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] num_training_samples: 4000\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] mini_batch_size: 48\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] image_shape: 3,224,224\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] num_classes: 2\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] augmentation_type: None\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] kv_store: device\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] checkpoint_frequency not set, will store the best model\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] --------------------\n",
      "[05:52:45] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\n",
      "[05:52:45] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\n",
      "/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      "[05/24/2025 05:52:45 INFO 140453719336768] Setting number of threads: 3\n",
      "[05:52:51] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.4.x_ecl_Cuda_11.1.x.441.0/AL2_x86_64/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[05/24/2025 05:53:14 INFO 140453719336768] Epoch[0] Batch [20]#011Speed: 40.968 samples/sec#011accuracy=0.755952\n",
      "[05/24/2025 05:53:35 INFO 140453719336768] Epoch[0] Batch [40]#011Speed: 44.050 samples/sec#011accuracy=0.875000\n",
      "[05/24/2025 05:53:55 INFO 140453719336768] Epoch[0] Batch [60]#011Speed: 45.114 samples/sec#011accuracy=0.743169\n",
      "[05/24/2025 05:54:15 INFO 140453719336768] Epoch[0] Batch [80]#011Speed: 45.628 samples/sec#011accuracy=0.806327\n",
      "[05/24/2025 05:54:17 INFO 140453719336768] Epoch[0] Train-accuracy=0.810994\n",
      "[05/24/2025 05:54:17 INFO 140453719336768] Epoch[0] Time cost=86.199\n",
      "[05/24/2025 05:54:25 INFO 140453719336768] Epoch[0] Validation-accuracy=0.396825\n",
      "[05/24/2025 05:54:25 INFO 140453719336768] Storing the best model with validation accuracy: 0.396825\n",
      "[05/24/2025 05:54:25 INFO 140453719336768] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\n",
      "[05/24/2025 05:54:46 INFO 140453719336768] Epoch[1] Batch [20]#011Speed: 46.342 samples/sec#011accuracy=0.350198\n",
      "[05/24/2025 05:55:06 INFO 140453719336768] Epoch[1] Batch [40]#011Speed: 46.682 samples/sec#011accuracy=0.667175\n",
      "[05/24/2025 05:55:27 INFO 140453719336768] Epoch[1] Batch [60]#011Speed: 46.778 samples/sec#011accuracy=0.585041\n",
      "[05/24/2025 05:55:47 INFO 140453719336768] Epoch[1] Batch [80]#011Speed: 46.851 samples/sec#011accuracy=0.649177\n",
      "[05/24/2025 05:55:49 INFO 140453719336768] Epoch[1] Train-accuracy=0.653614\n",
      "[05/24/2025 05:55:49 INFO 140453719336768] Epoch[1] Time cost=84.002\n",
      "[05/24/2025 05:55:57 INFO 140453719336768] Epoch[1] Validation-accuracy=0.396825\n",
      "[05/24/2025 05:56:18 INFO 140453719336768] Epoch[2] Batch [20]#011Speed: 45.969 samples/sec#011accuracy=0.285714\n",
      "[05/24/2025 05:56:38 INFO 140453719336768] Epoch[2] Batch [40]#011Speed: 46.498 samples/sec#011accuracy=0.634146\n",
      "[05/24/2025 05:56:59 INFO 140453719336768] Epoch[2] Batch [60]#011Speed: 46.665 samples/sec#011accuracy=0.568306\n",
      "[05/24/2025 05:57:19 INFO 140453719336768] Epoch[2] Batch [80]#011Speed: 46.760 samples/sec#011accuracy=0.620113\n",
      "[05/24/2025 05:57:21 INFO 140453719336768] Epoch[2] Train-accuracy=0.629267\n",
      "[05/24/2025 05:57:21 INFO 140453719336768] Epoch[2] Time cost=84.161\n",
      "[05/24/2025 05:57:29 INFO 140453719336768] Epoch[2] Validation-accuracy=0.396825\n",
      "[05/24/2025 05:57:50 INFO 140453719336768] Epoch[3] Batch [20]#011Speed: 45.420 samples/sec#011accuracy=0.238095\n",
      "[05/24/2025 05:58:11 INFO 140453719336768] Epoch[3] Batch [40]#011Speed: 46.214 samples/sec#011accuracy=0.609756\n",
      "[05/24/2025 05:58:31 INFO 140453719336768] Epoch[3] Batch [60]#011Speed: 46.494 samples/sec#011accuracy=0.557377\n",
      "[05/24/2025 05:58:51 INFO 140453719336768] Epoch[3] Batch [80]#011Speed: 46.658 samples/sec#011accuracy=0.598251\n",
      "[05/24/2025 05:58:53 INFO 140453719336768] Epoch[3] Train-accuracy=0.607932\n",
      "[05/24/2025 05:58:53 INFO 140453719336768] Epoch[3] Time cost=84.336\n",
      "[05/24/2025 05:59:01 INFO 140453719336768] Epoch[3] Validation-accuracy=0.396825\n",
      "[05/24/2025 05:59:22 INFO 140453719336768] Epoch[4] Batch [20]#011Speed: 46.132 samples/sec#011accuracy=0.198413\n",
      "[05/24/2025 05:59:42 INFO 140453719336768] Epoch[4] Batch [40]#011Speed: 46.581 samples/sec#011accuracy=0.589431\n",
      "[05/24/2025 06:00:03 INFO 140453719336768] Epoch[4] Batch [60]#011Speed: 46.747 samples/sec#011accuracy=0.532787\n",
      "[05/24/2025 06:00:23 INFO 140453719336768] Epoch[4] Batch [80]#011Speed: 46.824 samples/sec#011accuracy=0.585648\n",
      "[05/24/2025 06:00:25 INFO 140453719336768] Epoch[4] Train-accuracy=0.591616\n",
      "[05/24/2025 06:00:25 INFO 140453719336768] Epoch[4] Time cost=84.047\n",
      "[05/24/2025 06:00:33 INFO 140453719336768] Epoch[4] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:00:54 INFO 140453719336768] Epoch[5] Batch [20]#011Speed: 46.240 samples/sec#011accuracy=0.223214\n",
      "[05/24/2025 06:01:14 INFO 140453719336768] Epoch[5] Batch [40]#011Speed: 46.635 samples/sec#011accuracy=0.602134\n",
      "[05/24/2025 06:01:35 INFO 140453719336768] Epoch[5] Batch [60]#011Speed: 46.756 samples/sec#011accuracy=0.546790\n",
      "[05/24/2025 06:01:55 INFO 140453719336768] Epoch[5] Batch [80]#011Speed: 46.854 samples/sec#011accuracy=0.592593\n",
      "[05/24/2025 06:01:57 INFO 140453719336768] Epoch[5] Train-accuracy=0.602410\n",
      "[05/24/2025 06:01:57 INFO 140453719336768] Epoch[5] Time cost=83.992\n",
      "[05/24/2025 06:02:04 INFO 140453719336768] Epoch[5] Validation-accuracy=0.416667\n",
      "[05/24/2025 06:02:04 INFO 140453719336768] Storing the best model with validation accuracy: 0.416667\n",
      "[05/24/2025 06:02:05 INFO 140453719336768] Saved checkpoint to \"/opt/ml/model/image-classification-0006.params\"\n",
      "[05/24/2025 06:02:26 INFO 140453719336768] Epoch[6] Batch [20]#011Speed: 45.579 samples/sec#011accuracy=0.231151\n",
      "[05/24/2025 06:02:46 INFO 140453719336768] Epoch[6] Batch [40]#011Speed: 46.357 samples/sec#011accuracy=0.606199\n",
      "[05/24/2025 06:03:06 INFO 140453719336768] Epoch[6] Batch [60]#011Speed: 46.609 samples/sec#011accuracy=0.554986\n",
      "[05/24/2025 06:03:27 INFO 140453719336768] Epoch[6] Batch [80]#011Speed: 46.747 samples/sec#011accuracy=0.594136\n",
      "[05/24/2025 06:03:29 INFO 140453719336768] Epoch[6] Train-accuracy=0.603916\n",
      "[05/24/2025 06:03:29 INFO 140453719336768] Epoch[6] Time cost=84.180\n",
      "[05/24/2025 06:03:36 INFO 140453719336768] Epoch[6] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:03:57 INFO 140453719336768] Epoch[7] Batch [20]#011Speed: 46.269 samples/sec#011accuracy=0.216270\n",
      "[05/24/2025 06:04:18 INFO 140453719336768] Epoch[7] Batch [40]#011Speed: 46.673 samples/sec#011accuracy=0.598577\n",
      "[05/24/2025 06:04:38 INFO 140453719336768] Epoch[7] Batch [60]#011Speed: 46.832 samples/sec#011accuracy=0.538934\n",
      "[05/24/2025 06:04:58 INFO 140453719336768] Epoch[7] Batch [80]#011Speed: 46.929 samples/sec#011accuracy=0.587963\n",
      "[05/24/2025 06:05:00 INFO 140453719336768] Epoch[7] Train-accuracy=0.593876\n",
      "[05/24/2025 06:05:00 INFO 140453719336768] Epoch[7] Time cost=83.866\n",
      "[05/24/2025 06:05:08 INFO 140453719336768] Epoch[7] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:05:29 INFO 140453719336768] Epoch[8] Batch [20]#011Speed: 46.167 samples/sec#011accuracy=0.256944\n",
      "[05/24/2025 06:05:49 INFO 140453719336768] Epoch[8] Batch [40]#011Speed: 46.642 samples/sec#011accuracy=0.619411\n",
      "[05/24/2025 06:06:10 INFO 140453719336768] Epoch[8] Batch [60]#011Speed: 46.792 samples/sec#011accuracy=0.558402\n",
      "[05/24/2025 06:06:30 INFO 140453719336768] Epoch[8] Batch [80]#011Speed: 46.882 samples/sec#011accuracy=0.613169\n",
      "[05/24/2025 06:06:32 INFO 140453719336768] Epoch[8] Train-accuracy=0.622490\n",
      "[05/24/2025 06:06:32 INFO 140453719336768] Epoch[8] Time cost=83.941\n",
      "[05/24/2025 06:06:40 INFO 140453719336768] Epoch[8] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:07:01 INFO 140453719336768] Epoch[9] Batch [20]#011Speed: 45.489 samples/sec#011accuracy=0.287698\n",
      "[05/24/2025 06:07:21 INFO 140453719336768] Epoch[9] Batch [40]#011Speed: 46.298 samples/sec#011accuracy=0.635163\n",
      "[05/24/2025 06:07:42 INFO 140453719336768] Epoch[9] Batch [60]#011Speed: 46.566 samples/sec#011accuracy=0.574454\n",
      "[05/24/2025 06:08:02 INFO 140453719336768] Epoch[9] Batch [80]#011Speed: 46.704 samples/sec#011accuracy=0.625000\n",
      "[05/24/2025 06:08:04 INFO 140453719336768] Epoch[9] Train-accuracy=0.634036\n",
      "[05/24/2025 06:08:04 INFO 140453719336768] Epoch[9] Time cost=84.259\n",
      "[05/24/2025 06:08:12 INFO 140453719336768] Epoch[9] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:08:33 INFO 140453719336768] Epoch[10] Batch [20]#011Speed: 46.170 samples/sec#011accuracy=0.333333\n",
      "[05/24/2025 06:08:53 INFO 140453719336768] Epoch[10] Batch [40]#011Speed: 46.645 samples/sec#011accuracy=0.658537\n",
      "[05/24/2025 06:09:13 INFO 140453719336768] Epoch[10] Batch [60]#011Speed: 46.783 samples/sec#011accuracy=0.579235\n",
      "[05/24/2025 06:09:34 INFO 140453719336768] Epoch[10] Batch [80]#011Speed: 46.876 samples/sec#011accuracy=0.657150\n",
      "[05/24/2025 06:09:36 INFO 140453719336768] Epoch[10] Train-accuracy=0.661396\n",
      "[05/24/2025 06:09:36 INFO 140453719336768] Epoch[10] Time cost=83.953\n",
      "[05/24/2025 06:09:43 INFO 140453719336768] Epoch[10] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:10:04 INFO 140453719336768] Epoch[11] Batch [20]#011Speed: 46.158 samples/sec#011accuracy=0.455357\n",
      "[05/24/2025 06:10:25 INFO 140453719336768] Epoch[11] Batch [40]#011Speed: 46.631 samples/sec#011accuracy=0.721037\n",
      "[05/24/2025 06:10:45 INFO 140453719336768] Epoch[11] Batch [60]#011Speed: 46.800 samples/sec#011accuracy=0.645150\n",
      "[05/24/2025 06:11:05 INFO 140453719336768] Epoch[11] Batch [80]#011Speed: 46.892 samples/sec#011accuracy=0.730710\n",
      "[05/24/2025 06:11:07 INFO 140453719336768] Epoch[11] Train-accuracy=0.737199\n",
      "[05/24/2025 06:11:07 INFO 140453719336768] Epoch[11] Time cost=83.928\n",
      "[05/24/2025 06:11:15 INFO 140453719336768] Epoch[11] Validation-accuracy=0.416667\n",
      "[05/24/2025 06:11:36 INFO 140453719336768] Epoch[12] Batch [20]#011Speed: 45.505 samples/sec#011accuracy=0.732143\n",
      "[05/24/2025 06:11:56 INFO 140453719336768] Epoch[12] Batch [40]#011Speed: 46.289 samples/sec#011accuracy=0.862805\n",
      "[05/24/2025 06:12:17 INFO 140453719336768] Epoch[12] Batch [60]#011Speed: 46.562 samples/sec#011accuracy=0.834699\n",
      "[05/24/2025 06:12:37 INFO 140453719336768] Epoch[12] Batch [80]#011Speed: 46.719 samples/sec#011accuracy=0.870113\n",
      "[05/24/2025 06:12:39 INFO 140453719336768] Epoch[12] Train-accuracy=0.873243\n",
      "[05/24/2025 06:12:39 INFO 140453719336768] Epoch[12] Time cost=84.227\n",
      "[05/24/2025 06:12:47 INFO 140453719336768] Epoch[12] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:13:08 INFO 140453719336768] Epoch[13] Batch [20]#011Speed: 46.115 samples/sec#011accuracy=0.883929\n",
      "[05/24/2025 06:13:28 INFO 140453719336768] Epoch[13] Batch [40]#011Speed: 46.597 samples/sec#011accuracy=0.940549\n",
      "[05/24/2025 06:13:48 INFO 140453719336768] Epoch[13] Batch [60]#011Speed: 46.755 samples/sec#011accuracy=0.848702\n",
      "[05/24/2025 06:14:09 INFO 140453719336768] Epoch[13] Batch [80]#011Speed: 46.841 samples/sec#011accuracy=0.885288\n",
      "[05/24/2025 06:14:11 INFO 140453719336768] Epoch[13] Train-accuracy=0.884036\n",
      "[05/24/2025 06:14:11 INFO 140453719336768] Epoch[13] Time cost=84.022\n",
      "[05/24/2025 06:14:18 INFO 140453719336768] Epoch[13] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:14:39 INFO 140453719336768] Epoch[14] Batch [20]#011Speed: 46.223 samples/sec#011accuracy=0.300595\n",
      "[05/24/2025 06:15:00 INFO 140453719336768] Epoch[14] Batch [40]#011Speed: 46.650 samples/sec#011accuracy=0.641768\n",
      "[05/24/2025 06:15:20 INFO 140453719336768] Epoch[14] Batch [60]#011Speed: 46.793 samples/sec#011accuracy=0.573429\n",
      "[05/24/2025 06:15:41 INFO 140453719336768] Epoch[14] Batch [80]#011Speed: 46.882 samples/sec#011accuracy=0.617798\n",
      "[05/24/2025 06:15:43 INFO 140453719336768] Epoch[14] Train-accuracy=0.627008\n",
      "[05/24/2025 06:15:43 INFO 140453719336768] Epoch[14] Time cost=83.941\n",
      "[05/24/2025 06:15:50 INFO 140453719336768] Epoch[14] Validation-accuracy=0.396825\n",
      "[05/24/2025 06:16:11 INFO 140453719336768] Epoch[15] Batch [20]#011Speed: 45.550 samples/sec#011accuracy=0.424603\n",
      "[05/24/2025 06:16:32 INFO 140453719336768] Epoch[15] Batch [40]#011Speed: 46.316 samples/sec#011accuracy=0.705285\n",
      "[05/24/2025 06:16:52 INFO 140453719336768] Epoch[15] Batch [60]#011Speed: 46.572 samples/sec#011accuracy=0.637637\n",
      "\n",
      "2025-05-24 06:17:14 Stopping - Stopping the training job\n",
      "2025-05-24 06:17:14 Uploading - Uploading generated training model[05/24/2025 06:17:10 INFO 140453719336768] Training stopped.\n",
      "\n",
      "2025-05-24 06:17:27 Stopped - Training job stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 1721\n",
      "Billable seconds: 1721\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uris = {\n",
    "    \"VGG16\": f'{s3_output_path}/VGG16-20250519-1337-2025-05-19-18-37-49-859/output/model.tar.gz',\n",
    "    \"ResNet\": f'{s3_output_path}/pytorch-training-2025-05-19-18-03-50-824/output/model.tar.gz',\n",
    "    \"SimpleCNN\":   f'{s3_output_path}/SimpleCNN-20250519-1700-2025-05-19-22-00-59-316/output/model.tar.gz'\n",
    "}\n",
    "ensemble_models = {'MODEL_PATHS':\n",
    "                f'{s3_output_path}/VGG16-20250519-1337-2025-05-19-18-37-49-859/output/model.tar.gz,'\n",
    "                f'{s3_output_path}/pytorch-training-2025-05-19-18-03-50-824/output/model.tar.gz,'\n",
    "                f'{s3_output_path}/SimpleCNN-20250519-1700-2025-05-19-22-00-59-316/output/model.tar.gz',\n",
    "                'MODEL_WEIGHTS': '0.2,0.5,0.3'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "\n",
    "sagemaker_runtime = boto3.client(\n",
    "    \"sagemaker-runtime\", region_name=region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri =\t\"763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:2.0.0-gpu-py310-cu118-ubuntu20.04-sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data='s3://pitahaya-classification/placehordes/placeholder.tar.gz',\n",
    "    role=role_arn,\n",
    "    entry_point=\"inference.py\",\n",
    "    framework_version='2.0.0',\n",
    "    py_version='py39',\n",
    "    source_dir='code',\n",
    "    image_uri = image_uri,\n",
    "    env=ensemble_models,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mme = MultiDataModel(\n",
    "    name=\"PitahayaEnsemble\",\n",
    "    model_data_prefix=f\"{bucket}ensemble_models/\",\n",
    "    model=model,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for model_name, model_uri in model_uris.items():\n",
    "    mme.add_model(\n",
    "        model_data_source=model_uri,  \n",
    "        model_data_path=model_name    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name=\"Pitahaya-classification-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor = mme.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar nuevo modelo\n",
    "mme.add_model(model_data_source=f\"{bucket}/output/model/modelo.tar.gz\", model_data_path=\"nuevo-modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'data/normal/Fresh_Dragon_Augmented_Data0003.jpg'\n",
    "image = Image.open(image_path)\n",
    "image = image.resize((224, 224))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer la predicción llamando al endpoint\n",
    "response = sagemaker_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/jpeg\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(response['Body'].read().decode())\n",
    "print(f\"Resultado de la predicción: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para visualizar imágenes con predicciones\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de algunas imágenes con predicciones\n",
    "model.eval()\n",
    "inputs, classes = next(iter(dataloaders['val']))\n",
    "inputs = inputs.to(device)\n",
    "classes = classes.to(device)\n",
    "\n",
    "outputs = model(inputs)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(min(batch_size, len(inputs))):\n",
    "    ax = plt.subplot(min(batch_size, len(inputs)) // 8, 8, i + 1)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'predicted: {class_names[preds[i]]}\\ntrue: {class_names[classes[i]]}')\n",
    "    imshow(inputs.cpu().data[i])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOSCALING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoscaling = boto3.client('application-autoscaling')\n",
    "\n",
    "resource_id = f\"endpoint/pitahaya-ensemble-endpoint/variant/AllTraffic\"\n",
    "\n",
    "autoscaling.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
